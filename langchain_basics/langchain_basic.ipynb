{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ab26cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd9237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU \"langchain[groq]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a651b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221715b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Not much! Just here and ready to chat. Is there something on your mind that you'd like to talk about or ask about? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 38, 'total_tokens': 71, 'completion_time': 0.088054167, 'prompt_time': 0.002869696, 'queue_time': 0.050019064, 'total_time': 0.090923863}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a324d553-530e-487c-962d-b276de466ac6-0', usage_metadata={'input_tokens': 38, 'output_tokens': 33, 'total_tokens': 71})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702829cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Matrix Multiplication in Python**\\n=====================================\\n\\nBelow is a Python code snippet that multiplies two matrices of arbitrary but compatible order. It uses the NumPy library for matrix operations and checks if the matrix dimensions are compatible for multiplication.\\n\\n```python\\nimport numpy as np\\n\\ndef multiply_matrices(mat1, mat2):\\n    \"\"\"\\n    Multiply two matrices of compatible order.\\n\\n    Args:\\n        mat1 (list): The first matrix.\\n        mat2 (list): The second matrix.\\n\\n    Returns:\\n        np.ndarray: The product of the two matrices.\\n\\n    Raises:\\n        ValueError: If the matrix dimensions are not compatible for multiplication.\\n    \"\"\"\\n    # Check if the input matrices are lists\\n    if not isinstance(mat1, list) or not isinstance(mat2, list):\\n        raise ValueError(\"Input matrices must be lists\")\\n\\n    # Convert input lists to NumPy arrays\\n    mat1 = np.array(mat1)\\n    mat2 = np.array(mat2)\\n\\n    # Check if the matrix dimensions are compatible for multiplication\\n    if mat1.shape[1] != mat2.shape[0]:\\n        raise ValueError(\"Matrix dimensions are not compatible for multiplication\")\\n\\n    # Multiply the matrices\\n    product = np.matmul(mat1, mat2)\\n\\n    return product\\n\\n# Example usage:\\nif __name__ == \"__main__\":\\n    # Define two matrices\\n    mat1 = [[1, 2, 3], [4, 5, 6]]\\n    mat2 = [[7, 8], [9, 10], [11, 12]]\\n\\n    try:\\n        # Multiply the matrices\\n        product = multiply_matrices(mat1, mat2)\\n        print(\"Matrix Product:\")\\n        print(product)\\n    except ValueError as e:\\n        print(\"Error:\", e)\\n```\\n\\n**Explanation**\\n---------------\\n\\n1.  The `multiply_matrices` function takes two input matrices `mat1` and `mat2`.\\n2.  It checks if the input matrices are lists and converts them to NumPy arrays.\\n3.  The function then checks if the matrix dimensions are compatible for multiplication by verifying that the number of columns in the first matrix (`mat1.shape[1]`) is equal to the number of rows in the second matrix (`mat2.shape[0]`).\\n4.  If the dimensions are compatible, it multiplies the matrices using the `np.matmul` function and returns the product.\\n5.  If the dimensions are not compatible, it raises a `ValueError` with a descriptive error message.\\n6.  In the example usage section, two matrices `mat1` and `mat2` are defined, and the `multiply_matrices` function is called to compute their product. The result is printed to the console. If an error occurs, the error message is displayed.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 567, 'prompt_tokens': 68, 'total_tokens': 635, 'completion_time': 1.002759717, 'prompt_time': 0.003213078, 'queue_time': 0.048164741, 'total_time': 1.005972795}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--8154725f-9d9c-4b71-b0cc-bcf8433afc34-0', usage_metadata={'input_tokens': 68, 'output_tokens': 567, 'total_tokens': 635})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"\"\" Write a python code which can multiply two matrix of arbitrary but compatible order. The code should throw exception if the matrix dimentsions are not compatible for multiplication             \n",
    "             \"\"\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbce870f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Matrix Multiplication in Python**\n",
      "=====================================\n",
      "\n",
      "Below is a Python code snippet that multiplies two matrices of arbitrary but compatible order. It uses the NumPy library for matrix operations and checks if the matrix dimensions are compatible for multiplication.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def multiply_matrices(mat1, mat2):\n",
      "    \"\"\"\n",
      "    Multiply two matrices of compatible order.\n",
      "\n",
      "    Args:\n",
      "        mat1 (list): The first matrix.\n",
      "        mat2 (list): The second matrix.\n",
      "\n",
      "    Returns:\n",
      "        np.ndarray: The product of the two matrices.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the matrix dimensions are not compatible for multiplication.\n",
      "    \"\"\"\n",
      "    # Check if the input matrices are lists\n",
      "    if not isinstance(mat1, list) or not isinstance(mat2, list):\n",
      "        raise ValueError(\"Input matrices must be lists\")\n",
      "\n",
      "    # Convert input lists to NumPy arrays\n",
      "    mat1 = np.array(mat1)\n",
      "    mat2 = np.array(mat2)\n",
      "\n",
      "    # Check if the matrix dimensions are compatible for multiplication\n",
      "    if mat1.shape[1] != mat2.shape[0]:\n",
      "        raise ValueError(\"Matrix dimensions are not compatible for multiplication\")\n",
      "\n",
      "    # Multiply the matrices\n",
      "    product = np.matmul(mat1, mat2)\n",
      "\n",
      "    return product\n",
      "\n",
      "# Example usage:\n",
      "if __name__ == \"__main__\":\n",
      "    # Define two matrices\n",
      "    mat1 = [[1, 2, 3], [4, 5, 6]]\n",
      "    mat2 = [[7, 8], [9, 10], [11, 12]]\n",
      "\n",
      "    try:\n",
      "        # Multiply the matrices\n",
      "        product = multiply_matrices(mat1, mat2)\n",
      "        print(\"Matrix Product:\")\n",
      "        print(product)\n",
      "    except ValueError as e:\n",
      "        print(\"Error:\", e)\n",
      "```\n",
      "\n",
      "**Explanation**\n",
      "---------------\n",
      "\n",
      "1.  The `multiply_matrices` function takes two input matrices `mat1` and `mat2`.\n",
      "2.  It checks if the input matrices are lists and converts them to NumPy arrays.\n",
      "3.  The function then checks if the matrix dimensions are compatible for multiplication by verifying that the number of columns in the first matrix (`mat1.shape[1]`) is equal to the number of rows in the second matrix (`mat2.shape[0]`).\n",
      "4.  If the dimensions are compatible, it multiplies the matrices using the `np.matmul` function and returns the product.\n",
      "5.  If the dimensions are not compatible, it raises a `ValueError` with a descriptive error message.\n",
      "6.  In the example usage section, two matrices `mat1` and `mat2` are defined, and the `multiply_matrices` function is called to compute their product. The result is printed to the console. If an error occurs, the error message is displayed.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038fa25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='হাই!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 45, 'total_tokens': 51, 'completion_time': 0.026364204, 'prompt_time': 0.002458714, 'queue_time': 0.053077946, 'total_time': 0.028822918}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5b0e2ef4-bd51-4c61-9c96-2ee79ff0442d-0', usage_metadata={'input_tokens': 45, 'output_tokens': 6, 'total_tokens': 51})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Bengali\"), # try punjabi, or any other Indian language\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba168e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"Generate python code for given tasks\"),\n",
    "    HumanMessage(\"Find max of given n numbers\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c1e861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Finding the Maximum of N Numbers in Python**\n",
      "=====================================================\n",
      "\n",
      "Here's a Python function that finds the maximum of N numbers:\n",
      "\n",
      "```python\n",
      "def find_max(numbers):\n",
      "    \"\"\"\n",
      "    Finds the maximum of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        numbers (list): A list of numbers.\n",
      "\n",
      "    Returns:\n",
      "        int: The maximum number in the list.\n",
      "    \"\"\"\n",
      "    return max(numbers)\n",
      "\n",
      "# Example usage\n",
      "numbers = [12, 45, 7, 23, 56, 89, 34]\n",
      "max_number = find_max(numbers)\n",
      "print(f\"The maximum number is: {max_number}\")\n",
      "```\n",
      "\n",
      "**How it Works**\n",
      "---------------\n",
      "\n",
      "1. The `find_max` function takes a list of numbers as input.\n",
      "2. The built-in `max` function is used to find the maximum number in the list.\n",
      "3. The maximum number is returned by the function.\n",
      "\n",
      "**Alternative Implementation**\n",
      "---------------------------\n",
      "\n",
      "If you want to implement the maximum finding logic manually, you can use the following code:\n",
      "\n",
      "```python\n",
      "def find_max_manual(numbers):\n",
      "    \"\"\"\n",
      "    Finds the maximum of a list of numbers manually.\n",
      "\n",
      "    Args:\n",
      "        numbers (list): A list of numbers.\n",
      "\n",
      "    Returns:\n",
      "        int: The maximum number in the list.\n",
      "    \"\"\"\n",
      "    max_number = numbers[0]\n",
      "    for num in numbers[1:]:\n",
      "        if num > max_number:\n",
      "            max_number = num\n",
      "    return max_number\n",
      "\n",
      "# Example usage\n",
      "numbers = [12, 45, 7, 23, 56, 89, 34]\n",
      "max_number = find_max_manual(numbers)\n",
      "print(f\"The maximum number is: {max_number}\")\n",
      "```\n",
      "\n",
      "**Time Complexity**\n",
      "-----------------\n",
      "\n",
      "The time complexity of the `find_max` function is O(n), where n is the number of elements in the list. This is because the `max` function iterates over all elements in the list to find the maximum.\n",
      "\n",
      "The time complexity of the `find_max_manual` function is also O(n), as it iterates over all elements in the list to find the maximum.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24dc4733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Finding the Maximum of N Numbers in Python**\n",
      "=====================================================\n",
      "\n",
      "Here's a Python function that finds the maximum of N numbers:\n",
      "\n",
      "```python\n",
      "def find_max(numbers):\n",
      "    \"\"\"\n",
      "    Finds the maximum of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        numbers (list): A list of numbers.\n",
      "\n",
      "    Returns:\n",
      "        int: The maximum number in the list.\n",
      "    \"\"\"\n",
      "    return max(numbers)\n",
      "\n",
      "# Example usage\n",
      "numbers = [12, 45, 7, 23, 56, 89, 34]\n",
      "max_number = find_max(numbers)\n",
      "print(f\"The maximum number is: {max_number}\")\n",
      "```\n",
      "\n",
      "**How it Works**\n",
      "---------------\n",
      "\n",
      "1. The `find_max` function takes a list of numbers as input.\n",
      "2. The built-in `max` function is used to find the maximum number in the list.\n",
      "3. The maximum number is returned by the function.\n",
      "\n",
      "**Alternative Implementation**\n",
      "---------------------------\n",
      "\n",
      "If you want to implement the maximum finding logic manually, you can use the following code:\n",
      "\n",
      "```python\n",
      "def find_max_manual(numbers):\n",
      "    \"\"\"\n",
      "    Finds the maximum of a list of numbers manually.\n",
      "\n",
      "    Args:\n",
      "        numbers (list): A list of numbers.\n",
      "\n",
      "    Returns:\n",
      "        int: The maximum number in the list.\n",
      "    \"\"\"\n",
      "    max_number = numbers[0]\n",
      "    for num in numbers[1:]:\n",
      "        if num > max_number:\n",
      "            max_number = num\n",
      "    return max_number\n",
      "\n",
      "# Example usage\n",
      "numbers = [12, 45, 7, 23, 56, 89, 34]\n",
      "max_number = find_max_manual(numbers)\n",
      "print(f\"The maximum number is: {max_number}\")\n",
      "```\n",
      "\n",
      "**Time Complexity**\n",
      "-----------------\n",
      "\n",
      "The time complexity of the `find_max` function is O(n), where n is the number of elements in the list. This is because the `max` function iterates over all elements in the list to find the maximum.\n",
      "\n",
      "The time complexity of the `find_max_manual` function is also O(n), as it iterates over all elements in the list to find the maximum.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f54949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content='Hello' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' It' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=\"'s\" additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' nice' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' meet' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' Is' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' there' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' something' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' I' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' can' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' help' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' or' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' would' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content=' chat' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content='?' additional_kwargs={} response_metadata={} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand'} id='run--91e948aa-322b-41a5-be4a-54f55e9d0365' usage_metadata={'input_tokens': 36, 'output_tokens': 25, 'total_tokens': 61}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for token in model.stream(\"hello\"):\n",
    "    time.sleep(0.1)\n",
    "    #print(token.content, end=\"|\")\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9259bfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseChatModel.stream at 0x000001925C88AA70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stream(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f0fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model1 = init_chat_model(\"meta-llama/llama-4-maverick-17b-128e-instruct\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016e5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
