{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3054bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d542213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a model\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e424c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def laugh() -> str:\n",
    "    \"\"\" Call this tool if the mood is funny\"\"\"\n",
    "    return \"HAHAHAHAHAH\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def sad() -> str:\n",
    "    \"\"\" Call this tool if you want to show sad, depressed, or negative feelings\"\"\"\n",
    "    return \"I am sad\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def happy() -> str:\n",
    "    \"\"\" Call this tool if you want to show happiness or positive feeling\"\"\"\n",
    "    return \"I am happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9f5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [laugh, sad, happy ]\n",
    "tools_dict = {t.name: t for t in tools_list} # comes in handy at the time of invokation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b113a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a tool calling Agent by binding a list of tools to the llm\n",
    "llm_with_tools = llm.bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd1519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "# This will store all converation\n",
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec89645c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"World is so mean?\"))\n",
    "\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e38e1d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7099c421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='48spkrf69')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c239575b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's1fzzf3pd', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.017476062, 'prompt_time': 0.032759086, 'queue_time': 0.051609014, 'total_time': 0.050235148}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e36bbbcc-c3ea-469a-950e-0f7f5754989b-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 's1fzzf3pd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"Thankfully, I have a girlfriend\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ea80aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='48spkrf69'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's1fzzf3pd', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.017476062, 'prompt_time': 0.032759086, 'queue_time': 0.051609014, 'total_time': 0.050235148}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e36bbbcc-c3ea-469a-950e-0f7f5754989b-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 's1fzzf3pd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37f1d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='48spkrf69'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's1fzzf3pd', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.017476062, 'prompt_time': 0.032759086, 'queue_time': 0.051609014, 'total_time': 0.050235148}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e36bbbcc-c3ea-469a-950e-0f7f5754989b-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 's1fzzf3pd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='s1fzzf3pd')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0641186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='48spkrf69'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's1fzzf3pd', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.017476062, 'prompt_time': 0.032759086, 'queue_time': 0.051609014, 'total_time': 0.050235148}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e36bbbcc-c3ea-469a-950e-0f7f5754989b-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 's1fzzf3pd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='s1fzzf3pd'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '69ahmrc1r', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.009614254, 'prompt_time': 0.034730993, 'queue_time': 0.065416596, 'total_time': 0.044345247}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b28ec469-e079-4eab-bd2c-291382e6ad85-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '69ahmrc1r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"But she is unfaithful?\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "778962f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='48spkrf69'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's1fzzf3pd', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.017476062, 'prompt_time': 0.032759086, 'queue_time': 0.051609014, 'total_time': 0.050235148}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e36bbbcc-c3ea-469a-950e-0f7f5754989b-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 's1fzzf3pd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='s1fzzf3pd'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '69ahmrc1r', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.009614254, 'prompt_time': 0.034730993, 'queue_time': 0.065416596, 'total_time': 0.044345247}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b28ec469-e079-4eab-bd2c-291382e6ad85-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '69ahmrc1r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '69ahmrc1r', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.009614254, 'prompt_time': 0.034730993, 'queue_time': 0.065416596, 'total_time': 0.044345247}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b28ec469-e079-4eab-bd2c-291382e6ad85-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '69ahmrc1r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ba0f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='48spkrf69'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's1fzzf3pd', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.017476062, 'prompt_time': 0.032759086, 'queue_time': 0.051609014, 'total_time': 0.050235148}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e36bbbcc-c3ea-469a-950e-0f7f5754989b-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 's1fzzf3pd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='s1fzzf3pd'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '69ahmrc1r', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.009614254, 'prompt_time': 0.034730993, 'queue_time': 0.065416596, 'total_time': 0.044345247}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b28ec469-e079-4eab-bd2c-291382e6ad85-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '69ahmrc1r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '69ahmrc1r', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.009614254, 'prompt_time': 0.034730993, 'queue_time': 0.065416596, 'total_time': 0.044345247}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b28ec469-e079-4eab-bd2c-291382e6ad85-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '69ahmrc1r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='69ahmrc1r')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the tool, append the response\n",
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1423994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '48spkrf69', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 351, 'total_tokens': 359, 'completion_time': 0.024893159, 'prompt_time': 0.029925581, 'queue_time': 0.045515469, 'total_time': 0.05481874}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2552864a-fe9d-4119-9797-8461c1212508-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '48spkrf69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 8, 'total_tokens': 359}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='48spkrf69'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 's1fzzf3pd', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 385, 'total_tokens': 394, 'completion_time': 0.017476062, 'prompt_time': 0.032759086, 'queue_time': 0.051609014, 'total_time': 0.050235148}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e36bbbcc-c3ea-469a-950e-0f7f5754989b-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 's1fzzf3pd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 385, 'output_tokens': 9, 'total_tokens': 394}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='s1fzzf3pd'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '69ahmrc1r', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.009614254, 'prompt_time': 0.034730993, 'queue_time': 0.065416596, 'total_time': 0.044345247}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b28ec469-e079-4eab-bd2c-291382e6ad85-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '69ahmrc1r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '69ahmrc1r', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 419, 'total_tokens': 428, 'completion_time': 0.009614254, 'prompt_time': 0.034730993, 'queue_time': 0.065416596, 'total_time': 0.044345247}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b28ec469-e079-4eab-bd2c-291382e6ad85-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': '69ahmrc1r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 419, 'output_tokens': 9, 'total_tokens': 428}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='69ahmrc1r'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes, you do have a girlfriend, but unfortunately, she is unfaithful.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 465, 'total_tokens': 483, 'completion_time': 0.056651028, 'prompt_time': 0.038532934, 'queue_time': 0.061799535, 'total_time': 0.095183962}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--44aeb1f2-6fe5-4299-9bcd-181087996326-0', usage_metadata={'input_tokens': 465, 'output_tokens': 18, 'total_tokens': 483})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see, if the model remebers the context\n",
    "chat_history.append(HumanMessage(content=\"Do I have a girlfriend?\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
