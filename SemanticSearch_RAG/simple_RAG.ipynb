{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06882e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a44a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Mudit is Bittu's brother. He is also the brother of Minni. Bittu and Minni are sisters, and Mudit is their male sibling.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 119, 'total_tokens': 155, 'completion_time': 0.115595549, 'prompt_time': 0.006663125, 'queue_time': 0.048789235, 'total_time': 0.122258674}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--a88807fd-860e-40d4-8e07-3a79c0a26463-0' usage_metadata={'input_tokens': 119, 'output_tokens': 36, 'total_tokens': 155}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "response = model.invoke(\n",
    "    prompt_template.format(\n",
    "        context=\"Mudit has two sisters, Bittu and Minni. Mudit is male.\",\n",
    "        question=\"Who is Bittu's bother?\"         \n",
    "    ))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42489729",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 285978: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m file = \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mindianTales.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m text = \u001b[43mfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'charmap' codec can't decode byte 0x81 in position 285978: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "file = open(\"indianTales.txt\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930897ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Prepare your prompt\u001b[39;00m\n\u001b[32m      5\u001b[39m prompt_template = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are a novel reader. You are given collection of stories:\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;132;01m{collection_of_stories}\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33mYou are tasked to make a list of story titles in this collection. Write a short summary for each story in Hindi Language. Skip the story from the list, if the story is not provided in the text. \u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = model.invoke(prompt_template.format(collection_of_stories = \u001b[43mtext\u001b[49m[:\u001b[38;5;28mlen\u001b[39m(text)//\u001b[32m20\u001b[39m]))\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mNameError\u001b[39m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "prompt_template = \"\"\"You are a novel reader. You are given collection of stories:\n",
    "{collection_of_stories}\n",
    "You are tasked to make a list of story titles in this collection. Write a short summary for each story in Hindi Language. Skip the story from the list, if the story is not provided in the text. \n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke(prompt_template.format(collection_of_stories = text[:len(text)//20]))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180a2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Mudit is Bittu's brother. He is also the brother of Minni. Mudit is the male sibling in the family."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184459f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[32m      2\u001b[39m loader = TextLoader(\u001b[33m\"\u001b[39m\u001b[33mindianTales.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m docs = loader.load()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"indianTales.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ab303",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m      3\u001b[39m text_splitter = RecursiveCharacterTextSplitter(\n\u001b[32m      4\u001b[39m     chunk_size=\u001b[32m1000\u001b[39m,  \u001b[38;5;66;03m# chunk size (characters)\u001b[39;00m\n\u001b[32m      5\u001b[39m     chunk_overlap=\u001b[32m200\u001b[39m,  \u001b[38;5;66;03m# chunk overlap (characters)\u001b[39;00m\n\u001b[32m      6\u001b[39m     add_start_index=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# track index in original document\u001b[39;00m\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m all_splits = text_splitter.split_documents(\u001b[43mdocs\u001b[49m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSplit given book into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_splits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sub-documents.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split given book into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038e01a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_google_genai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAIEmbeddings\n\u001b[32m      3\u001b[39m embeddings = GoogleGenerativeAIEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mmodels/embedding-001\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create a vector store\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# (CLASSROOM DISCUSSION: What are vector stores? What do we make them?)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_google_genai'"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Create a vector store\n",
    "# (CLASSROOM DISCUSSION: What are vector stores? What do we make them?)\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# Adding documents to vector store\n",
    "document_ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbc221",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m search_results = \u001b[43mvector_store\u001b[49m.similarity_search_with_score(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat is the role of Lion in the story?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     k = \u001b[32m10\u001b[39m\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "search_results = vector_store.similarity_search_with_score(\n",
    "    \"What is the role of Lion in the story?\",\n",
    "    k = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93a6c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msearch_results\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'search_results' is not defined"
     ]
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a90976",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d24886",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m doc_content = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(doc.page_content+\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m+\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m+\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (doc,score) \u001b[38;5;129;01min\u001b[39;00m \u001b[43msearch_results\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(doc_content)\n",
      "\u001b[31mNameError\u001b[39m: name 'search_results' is not defined"
     ]
    }
   ],
   "source": [
    "doc_content = \"\\n\\n\".join(doc.page_content+\"\\n\"+\"=\"*50+\"\\n\" for (doc,score) in search_results)\n",
    "print(doc_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba9f8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m model = init_chat_model(\u001b[33m\"\u001b[39m\u001b[33mllama-3.3-70b-versatile\u001b[39m\u001b[33m\"\u001b[39m, model_provider=\u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m prompt_template = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know the answer, just say that you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know. Use three sentences maximum and keep the answer concise.\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[33m \u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mContext: \u001b[39m\u001b[38;5;132;01m{context}\u001b[39;00m\u001b[33m \u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mAnswer:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      9\u001b[39m response = model.invoke(prompt_template.format(\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     context=\u001b[43mdoc_content\u001b[49m,\n\u001b[32m     11\u001b[39m     question=\u001b[33m\"\u001b[39m\u001b[33mWhat is the role of Lion in the story?\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'doc_content' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "\n",
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "response = model.invoke(prompt_template.format(\n",
    "    context=doc_content,\n",
    "    question=\"What is the role of Lion in the story?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab95c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Mudit is Bittu's brother. He is also the brother of Minni. Mudit is the male sibling in the family."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4d7a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[32m      2\u001b[39m loader = TextLoader(\u001b[33m\"\u001b[39m\u001b[33mindianTales.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m docs = loader.load()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"indianTales.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split document into small chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split given book into {len(all_splits)} sub-documents.\")\n",
    "\n",
    "# embedding\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Create a vector store\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# Adding documents to vector store\n",
    "document_ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c236c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m search_results = \u001b[43mvector_store\u001b[49m.similarity_search_with_score(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat is the role of Lion in the story?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     k = \u001b[32m10\u001b[39m\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m doc_content = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(doc.page_content+\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m+\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m+\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (doc,score) \u001b[38;5;129;01min\u001b[39;00m search_results)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(doc_content)\n",
      "\u001b[31mNameError\u001b[39m: name 'vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "search_results = vector_store.similarity_search_with_score(\n",
    "    \"What is the role of Lion in the story?\",\n",
    "    k = 10\n",
    ")\n",
    "\n",
    "doc_content = \"\\n\\n\".join(doc.page_content+\"\\n\"+\"=\"*50+\"\\n\" for (doc,score) in search_results)\n",
    "print(doc_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c403266",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m prompt_template = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know the answer, just say that you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know. Use three sentences maximum and keep the answer concise.\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[33m \u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mContext: \u001b[39m\u001b[38;5;132;01m{context}\u001b[39;00m\u001b[33m \u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mAnswer:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      6\u001b[39m response = model.invoke(prompt_template.format(\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     context=\u001b[43mdoc_content\u001b[49m,\n\u001b[32m      8\u001b[39m     question=\u001b[33m\"\u001b[39m\u001b[33mWhat is the role of Lion in the story?\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown\n\u001b[32m     12\u001b[39m Markdown(response.content)\n",
      "\u001b[31mNameError\u001b[39m: name 'doc_content' is not defined"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "response = model.invoke(prompt_template.format(\n",
    "    context=doc_content,\n",
    "    question=\"What is the role of Lion in the story?\"))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
